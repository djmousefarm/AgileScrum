{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djmousefarm/AgileScrum/blob/master/i_want_to_write_a_script_in_python_that_will_trac_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import hashlib\n",
        "\n",
        "def fetch_list_items(url, target_selector):\n",
        "    \"\"\"Fetches the text content of list items from a webpage.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        list_items = soup.select(target_selector)\n",
        "        return [item.text.strip() for item in list_items]\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching URL: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing HTML: {e}\")\n",
        "        return None\n",
        "\n",
        "def generate_list_hash(item_list):\n",
        "    \"\"\"Generates a hash of the list items to detect changes.\"\"\"\n",
        "    sorted_list = sorted(item_list)  # Sort to ensure consistent hashing regardless of order\n",
        "    combined_string = \"\".join(sorted_list).encode('utf-8')\n",
        "    return hashlib.sha256(combined_string).hexdigest()\n",
        "\n",
        "def track_list_changes(url, target_selector, check_interval_seconds=60):\n",
        "    \"\"\"Tracks changes in a list on a webpage and notifies of additions.\"\"\"\n",
        "    previous_list_hash = None\n",
        "    print(f\"Tracking list at {url} using selector '{target_selector}'. Checking every {check_interval_seconds} seconds. Press Ctrl+C to stop.\")\n",
        "\n",
        "    while True:\n",
        "        current_items = fetch_list_items(url, target_selector)\n",
        "\n",
        "        if current_items is not None:\n",
        "            current_hash = generate_list_hash(current_items)\n",
        "\n",
        "            if previous_list_hash is not None and current_hash != previous_list_hash:\n",
        "                # Compare the current list with the previous one to find additions\n",
        "                previous_set = set(previous_items)\n",
        "                current_set = set(current_items)\n",
        "                new_items = list(current_set - previous_set)\n",
        "\n",
        "                if new_items:\n",
        "                    print(\"\\n--- New item(s) added! ---\")\n",
        "                    for item in new_items:\n",
        "                        print(f\"- {item}\")\n",
        "                    print(\"-------------------------\\n\")\n",
        "\n",
        "            previous_list_hash = current_hash\n",
        "            previous_items = current_items\n",
        "\n",
        "        time.sleep(check_interval_seconds)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    target_url = input(\"Enter the URL of the webpage to track: \")\n",
        "    list_selector = input(\"Enter the CSS selector for the list items (e.g., 'ul li', 'ol li.item'): \")\n",
        "    interval = int(input(\"Enter the check interval in seconds (e.g., 30, 60): \"))\n",
        "\n",
        "    track_list_changes(target_url, list_selector, interval)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "JbSGWSB-FcLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to Use This Script:**\n",
        "\n",
        "1.  **Install Libraries:**\n",
        "    ```bash\n",
        "    pip install requests beautifulsoup4\n",
        "    ```\n",
        "\n",
        "2.  **Run the Script:**\n",
        "    ```bash\n",
        "    python your_script_name.py\n",
        "    ```\n",
        "\n",
        "3.  **Enter Information:** The script will prompt you for:\n",
        "    * **URL of the webpage:** The full URL of the page containing the list you want to monitor.\n",
        "    * **CSS selector for the list items:** This is crucial for BeautifulSoup to correctly identify the elements within the list. You'll need to inspect the webpage's HTML source to determine the appropriate selector. Examples:\n",
        "        * If the list is an unordered list (`<ul>`) and each item is an `<li>`, the selector would be `ul li`.\n",
        "        * If it's an ordered list (`<ol>`) with `<li>` items having a specific class like `item`, the selector would be `ol li.item`.\n",
        "        * If the list items are within `<div>` elements inside a specific `div` with ID `my-list`, the selector might be `#my-list div`.\n",
        "    * **Check interval in seconds:** How often you want the script to check the webpage for changes.\n",
        "\n",
        "**Explanation of the Code:**\n",
        "\n",
        "1.  **`fetch_list_items(url, target_selector)`:**\n",
        "    * Takes the webpage URL and a CSS selector as input.\n",
        "    * Uses `requests` to fetch the content of the webpage.\n",
        "    * Uses `BeautifulSoup` to parse the HTML content.\n",
        "    * Uses `soup.select(target_selector)` to find all HTML elements that match the provided CSS selector (these should be your list items).\n",
        "    * Extracts the text content (`.text`) of each list item, removes leading/trailing whitespace (`.strip()`), and returns a list of these text items.\n",
        "    * Includes error handling for network issues and HTML parsing errors.\n",
        "\n",
        "2.  **`generate_list_hash(item_list)`:**\n",
        "    * Takes a list of strings (the list items) as input.\n",
        "    * Sorts the list to ensure that the order of items doesn't affect the hash. This way, only the addition or removal of items will change the hash.\n",
        "    * Joins the sorted items into a single string and encodes it to UTF-8.\n",
        "    * Calculates the SHA-256 hash of the combined string using the `hashlib` library. This hash acts as a unique fingerprint of the list's content.\n",
        "\n",
        "3.  **`track_list_changes(url, target_selector, check_interval_seconds=60)`:**\n",
        "    * This is the main function that continuously monitors the webpage.\n",
        "    * Initializes `previous_list_hash` to `None`.\n",
        "    * Enters an infinite `while True` loop to periodically check the webpage.\n",
        "    * Inside the loop:\n",
        "        * Calls `fetch_list_items()` to get the current list items.\n",
        "        * If the fetching is successful:\n",
        "            * Calculates the `current_hash` of the current list.\n",
        "            * If `previous_list_hash` is not `None` (meaning it's not the first check) and the `current_hash` is different from the `previous_list_hash`:\n",
        "                * It means the list has changed.\n",
        "                * It compares the `previous_items` with the `current_items` using sets to efficiently find the new items (items present in the current list but not in the previous list).\n",
        "                * If `new_items` are found, it prints a notification and lists the newly added items.\n",
        "            * Updates `previous_list_hash` and `previous_items` for the next iteration.\n",
        "        * Pauses the execution for the specified `check_interval_seconds` using `time.sleep()`.\n",
        "    * The loop can be stopped by pressing `Ctrl+C` in the terminal.\n",
        "\n",
        "**Important Considerations:**\n",
        "\n",
        "* **Website Structure:** This script relies on the HTML structure of the webpage remaining consistent. If the website changes its layout or the way the list is presented, you'll need to update the CSS selector accordingly.\n",
        "* **Dynamic Content:** If the list on the webpage is loaded dynamically using JavaScript, this simple script might not work directly. In such cases, you might need to use more advanced techniques like Selenium or Puppeteer to render the JavaScript and then extract the data.\n",
        "* **Rate Limiting:** Be mindful of the website's terms of service and avoid making too many requests in a short period. Implement a reasonable `check_interval_seconds` to avoid overloading the server.\n",
        "* **Error Handling:** The script includes basic error handling for network and parsing issues, but you might want to add more robust error logging or handling as needed.\n",
        "* **Notifications:** Instead of just printing to the console, you could extend the script to send email or other types of notifications when a change is detected."
      ],
      "metadata": {
        "id": "5qPRhDO5FcLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"md-recitation\">\n",
        "  Sources\n",
        "  <ol>\n",
        "  <li><a href=\"https://dev.to/eswar108/web-scraping-using-python-1f4o\">https://dev.to/eswar108/web-scraping-using-python-1f4o</a></li>\n",
        "  <li><a href=\"https://github.com/ASoleBusinessMan/Web-Scraper\">https://github.com/ASoleBusinessMan/Web-Scraper</a></li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "4o5_FSGjFcLe"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}